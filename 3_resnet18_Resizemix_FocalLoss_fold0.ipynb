{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_resnet18_Resizemix_duplicate_FocalLoss_fold0.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rAIMmWFo2iKp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDvmIZJiQeha"},"source":["%%time\n","import zipfile\n","for i in [0, 1, 2, 3]:\n","    with zipfile.ZipFile(f'drive/MyDrive/OffroadSegmentation/data/train_images_A_{i}.zip') as existing_zip:\n","        existing_zip.extractall('train_images')\n","\n","with zipfile.ZipFile(f'drive/MyDrive/OffroadSegmentation/data/train_annotations_A.zip') as existing_zip:\n","    existing_zip.extractall('train_annotations')\n","\n","!cp -r drive/MyDrive/OffroadSegmentation/data/precision_test_images precision_test_images\n","\n","!pip install segmentation-models-pytorch \n","!pip install -U git+https://github.com/albu/albumentations --no-cache-dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0Y-RVMS_i9f"},"source":["!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch --no-cache-dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnBrMz5Mw4wo"},"source":["import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import glob\r\n","\r\n","from torch.utils.data import DataLoader\r\n","from torch.utils.data import Dataset as BaseDataset\r\n","\r\n","import torch\r\n","import numpy as np\r\n","import segmentation_models_pytorch as smp\r\n","\r\n","import albumentations as albu\r\n","from tqdm import tqdm\r\n","\r\n","from requests import get\r\n","filename = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].split('.')[0]\r\n","\r\n","df = pd.read_csv('/content//drive/MyDrive/Signate-OffroadSegmentation/data/5fold_validation.csv')\r\n","df['file_name'] = df['png_name']\r\n","\r\n","fold = int(filename.split('fold')[1])\r\n","t_df = df[df['type'] == 'train_images']\r\n","train_df = t_df[(t_df['nunique_type'] == 2) |\r\n","                ((t_df['fold'] != fold) & (t_df['nunique_type'] == 1))]\r\n","\r\n","valid_df = t_df[(t_df['fold'] == fold) & (t_df['nunique_type'] == 1)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kr7vhWqpVWVH"},"source":["import random\r\n","def set_seed(seed: int = 42):\r\n","    random.seed(seed)\r\n","    np.random.seed(seed)\r\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\r\n","    torch.manual_seed(seed)\r\n","    torch.cuda.manual_seed(seed)\r\n","    torch.backends.cudnn.deterministic = True\r\n","    torch.backends.cudnn.benchmark = False\r\n","set_seed()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09GrwUDFAq5P"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"utvbL9eGd7Q9"},"source":["class Dataset(BaseDataset):\r\n","    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\r\n","    \r\n","    Args:\r\n","        images_dir (str): path to images folder\r\n","        masks_dir (str): path to segmentation masks folder\r\n","        class_values (list): values of classes to extract from segmentation mask\r\n","        augmentation (albumentations.Compose): data transfromation pipeline \r\n","            (e.g. flip, scale, etc.)\r\n","        preprocessing (albumentations.Compose): data preprocessing \r\n","            (e.g. noralization, shape manipulation, etc.)\r\n","    \r\n","    \"\"\"\r\n","    \r\n","    \r\n","    def __init__(\r\n","            self, \r\n","            df, \r\n","            augmentation=None, \r\n","            preprocessing=None,\r\n","    ):\r\n","        self.images_fps = df['file_name'].values\r\n","        self.masks_fps = df['annotation'].values\r\n","                \r\n","        self.augmentation = augmentation\r\n","        self.preprocessing = preprocessing\r\n","    \r\n","    def __getitem__(self, i):\r\n","        \r\n","        # read data\r\n","        image = cv2.imread(self.images_fps[i])\r\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","        mask = cv2.imread(self.masks_fps[i])\r\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\r\n","\r\n","        anno_list = [[128, 64, 128], [255, 128, 128], [0, 0, 70]]  # road, dirt road, other obstacle\r\n","        masks = [((mask[:, :, 0] == a[0]) & (mask[:, :, 1] == a[1]) & (mask[:, :, 2] == a[2])) for a in anno_list]\r\n","        mask = np.stack(masks, axis=-1).astype('float')\r\n","\r\n","        # apply augmentations\r\n","        if self.augmentation:\r\n","            sample = self.augmentation(image=image, mask=mask)\r\n","            image, mask = sample['image'], sample['mask']\r\n","        \r\n","        # apply preprocessing\r\n","        if self.preprocessing:\r\n","            sample = self.preprocessing(image=image, mask=mask)\r\n","            image, mask = sample['image'], sample['mask']\r\n","            \r\n","        return image, mask\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.images_fps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-DiSGsv1VAp"},"source":["\r\n","def get_training_augmentation():\r\n","    IMAGE_SIZE = [1080, 1920]\r\n","    train_transform = [\r\n","        albu.Resize(*[1056, 1920]),\r\n","        albu.PadIfNeeded(1056, 1920),\r\n","        \r\n","\r\n","        # albu.HorizontalFlip(p=0.5),\r\n","\r\n","        # albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.8, border_mode=0),\r\n","\r\n","        # albu.PadIfNeeded(min_height=1080, min_width=1920, always_apply=True, border_mode=0),\r\n","        # albu.RandomCrop(height=960, width=960, always_apply=True),\r\n","        # albu.RandomCrop(height=IMAGE_SIZE[0], width=IMAGE_SIZE[0], always_apply=True),\r\n","\r\n","        # albu.IAAAdditiveGaussianNoise(p=0.2),\r\n","        # albu.IAAPerspective(p=0.5),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.CLAHE(p=1),\r\n","        #         albu.RandomBrightness(p=1),\r\n","        #         albu.RandomGamma(p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.IAASharpen(p=1),\r\n","        #         albu.Blur(blur_limit=3, p=1),\r\n","        #         albu.MotionBlur(blur_limit=3, p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.RandomContrast(p=1),\r\n","        #         albu.HueSaturationValue(p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","    ]\r\n","    return albu.Compose(train_transform)\r\n","\r\n","\r\n","def get_validation_augmentation():\r\n","    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\r\n","    IMAGE_SIZE = [1080, 1920]\r\n","    test_transform = [\r\n","        albu.Resize(*[1056, 1920]),\r\n","        albu.PadIfNeeded(1056, 1920)\r\n","    ]\r\n","    return albu.Compose(test_transform)\r\n","\r\n","\r\n","def to_tensor(x, **kwargs):\r\n","    return x.transpose(2, 0, 1).astype('float32')\r\n","\r\n","\r\n","def get_preprocessing(preprocessing_fn):\r\n","    \"\"\"Construct preprocessing transform\r\n","    \r\n","    Args:\r\n","        preprocessing_fn (callbale): data normalization function \r\n","            (can be specific for each pretrained neural network)\r\n","    Return:\r\n","        transform: albumentations.Compose\r\n","    \r\n","    \"\"\"\r\n","    \r\n","    _transform = [\r\n","        albu.Lambda(image=preprocessing_fn),\r\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\r\n","    ]\r\n","    return albu.Compose(_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yq9p7GwsOlxe"},"source":["def visualize(**images):\r\n","    \"\"\"PLot images in one row.\"\"\"\r\n","    n = len(images)\r\n","    plt.figure(figsize=(16, 5))\r\n","    for i, (name, image) in enumerate(images.items()):\r\n","        plt.subplot(1, n, i + 1)\r\n","        plt.xticks([])\r\n","        plt.yticks([])\r\n","        plt.title(' '.join(name.split('_')).title())\r\n","        plt.imshow(image)\r\n","    plt.show()\r\n","\r\n","augmented_dataset = Dataset(\r\n","    train_df,\r\n","    augmentation=get_training_augmentation(), \r\n",")\r\n","\r\n","\r\n","# same image with different random transforms\r\n","for i in range(3):\r\n","    image, mask = augmented_dataset[i]\r\n","    visualize(image=image, mask=mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXkGorc9AKPG"},"source":["ENCODER = 'resnet18'\r\n","ENCODER_WEIGHTS = 'imagenet'\r\n","ACTIVATION = 'softmax2d' # could be None for logits or 'softmax2d' for multicalss segmentation\r\n","DEVICE = 'cuda'\r\n","\r\n","# create segmentation model with pretrained encoder\r\n","model = smp.Unet(\r\n","    encoder_name=ENCODER, \r\n","    encoder_weights=ENCODER_WEIGHTS, \r\n","    in_channels=3,\r\n","    classes=3, \r\n","    activation=ACTIVATION,\r\n",")\r\n","\r\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\r\n","\r\n","train_dataset = Dataset(\r\n","    train_df, \r\n","    augmentation=get_training_augmentation(), \r\n","    preprocessing=get_preprocessing(preprocessing_fn),\r\n",")\r\n","\r\n","valid_dataset = Dataset(\r\n","    valid_df, \r\n","    augmentation=get_validation_augmentation(), \r\n","    preprocessing=get_preprocessing(preprocessing_fn),\r\n",")\r\n","\r\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=12)\r\n","valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=4)\r\n","\r\n","loss = smp.losses.FocalLoss('multilabel')\r\n","metrics = [\r\n","    smp.utils.metrics.IoU(threshold=0.5),\r\n","]\r\n","\r\n","optimizer = torch.optim.Adam([ \r\n","    dict(params=model.parameters(), lr=0.0001),\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQ9QRcogLHAc"},"source":["# focal loss, resizemix を使うためにsmpをすこし変更\r\n","\r\n","import sys\r\n","import torch\r\n","from tqdm import tqdm as tqdm\r\n","import torch.nn.functional as F\r\n","from segmentation_models_pytorch.utils.meter import AverageValueMeter\r\n","\r\n","def rand_bbox(size, lam):\r\n","    W = size[2]\r\n","    H = size[3]\r\n","    cut_rat = np.sqrt(1. - lam)\r\n","    cut_w = np.int(W * cut_rat)\r\n","    cut_h = np.int(H * cut_rat)\r\n","\r\n","    # uniform\r\n","    cx = np.random.randint(W)\r\n","    cy = np.random.randint(H)\r\n","\r\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\r\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\r\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\r\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\r\n","\r\n","    return bbx1, bby1, bbx2, bby2\r\n","\r\n","def resizeMix(data, targets, alpha=1):\r\n","    indices = torch.randperm(data.size(0))\r\n","    shuffled_data = data[indices]\r\n","    shuffled_targets1 = targets[indices]\r\n","\r\n","    lam = np.random.beta(alpha, alpha)\r\n","    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\r\n","\r\n","    resize_data = F.interpolate(data, [bbx2-bbx1, bby2-bby1])\r\n","    resize_targets = F.interpolate(targets, [bbx2-bbx1, bby2-bby1])\r\n","    data[:, :, bbx1:bbx2, bby1:bby2] = resize_data[indices, :, :, :]\r\n","    targets[:, :, bbx1:bbx2, bby1:bby2] = resize_targets[indices, :, :, :]\r\n","\r\n","    return data, targets\r\n","\r\n","\r\n","class Epoch:\r\n","\r\n","    def __init__(self, model, loss, metrics, stage_name, device='cpu', verbose=True):\r\n","        self.model = model\r\n","        self.loss = loss\r\n","        self.metrics = metrics\r\n","        self.stage_name = stage_name\r\n","        self.verbose = verbose\r\n","        self.device = device\r\n","\r\n","        self._to_device()\r\n","\r\n","    def _to_device(self):\r\n","        self.model.to(self.device)\r\n","        self.loss.to(self.device)\r\n","        for metric in self.metrics:\r\n","            metric.to(self.device)\r\n","\r\n","    def _format_logs(self, logs):\r\n","        str_logs = ['{} - {:.4}'.format(k, v) for k, v in logs.items()]\r\n","        s = ', '.join(str_logs)\r\n","        return s\r\n","\r\n","    def batch_update(self, x, y):\r\n","        raise NotImplementedError\r\n","\r\n","    def on_epoch_start(self):\r\n","        pass\r\n","\r\n","    def run(self, dataloader, n_epoch, epoch, train=True):\r\n","\r\n","        self.on_epoch_start()\r\n","\r\n","        logs = {}\r\n","        loss_meter = AverageValueMeter()\r\n","        metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}\r\n","\r\n","        with tqdm(dataloader, desc=self.stage_name, file=sys.stdout, disable=not (self.verbose)) as iterator:\r\n","            for x, y in iterator:\r\n","                x, y = x.to(self.device), y.to(self.device)\r\n","\r\n","                if (train) & (n_epoch - epoch) > 10:  # 最後の10回はresizemixなしで学習する\r\n","                    x, y = resizeMix(x, y)\r\n","\r\n","                loss, y_pred = self.batch_update(x, y)\r\n","\r\n","                # update loss logs\r\n","                loss_value = loss.cpu().detach().numpy()\r\n","                loss_meter.add(loss_value)\r\n","                # loss_logs = {self.loss.__name__: loss_meter.mean}\r\n","                loss_logs = {'FocalLoss': loss_meter.mean}\r\n","                logs.update(loss_logs)\r\n","\r\n","                # update metrics logs\r\n","                for metric_fn in self.metrics:\r\n","                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()\r\n","                    metrics_meters[metric_fn.__name__].add(metric_value)\r\n","                metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\r\n","                logs.update(metrics_logs)\r\n","\r\n","                if self.verbose:\r\n","                    s = self._format_logs(logs)\r\n","                    iterator.set_postfix_str(s)\r\n","\r\n","        return logs\r\n","\r\n","\r\n","class TrainEpoch(Epoch):\r\n","\r\n","    def __init__(self, model, loss, metrics, optimizer, device='cpu', verbose=True):\r\n","        super().__init__(\r\n","            model=model,\r\n","            loss=loss,\r\n","            metrics=metrics,\r\n","            stage_name='train',\r\n","            device=device,\r\n","            verbose=verbose,\r\n","        )\r\n","        self.optimizer = optimizer\r\n","\r\n","    def on_epoch_start(self):\r\n","        self.model.train()\r\n","\r\n","    def batch_update(self, x, y):\r\n","        self.optimizer.zero_grad()\r\n","        prediction = self.model.forward(x)\r\n","        loss = self.loss(prediction, y)\r\n","        loss.backward()\r\n","        self.optimizer.step()\r\n","        return loss, prediction\r\n","\r\n","\r\n","class ValidEpoch(Epoch):\r\n","\r\n","    def __init__(self, model, loss, metrics, device='cpu', verbose=True):\r\n","        super().__init__(\r\n","            model=model,\r\n","            loss=loss,\r\n","            metrics=metrics,\r\n","            stage_name='valid',\r\n","            device=device,\r\n","            verbose=verbose,\r\n","        )\r\n","\r\n","    def on_epoch_start(self):\r\n","        self.model.eval()\r\n","\r\n","    def batch_update(self, x, y):\r\n","        with torch.no_grad():\r\n","            prediction = self.model.forward(x)\r\n","            loss = self.loss(prediction, y)\r\n","        return loss, prediction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fmip3sMBZSH"},"source":["train_epoch = TrainEpoch(\r\n","    model, \r\n","    loss=loss, \r\n","    metrics=metrics, \r\n","    optimizer=optimizer,\r\n","    device=DEVICE,\r\n","    verbose=True,\r\n",")\r\n","\r\n","valid_epoch = ValidEpoch(\r\n","    model, \r\n","    loss=loss, \r\n","    metrics=metrics, \r\n","    device=DEVICE,\r\n","    verbose=True,\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-7zBTWuBcbA"},"source":["n_epoch = 50\r\n","max_score = 0\r\n","model_path = f'/content//drive/MyDrive/OffroadSegmentation/model/{filename}.pth'\r\n","\r\n","for i in range(0,50):\r\n","    \r\n","    print('\\nEpoch: {}'.format(i))\r\n","    train_logs = train_epoch.run(train_loader, n_epoch, i, train=True)\r\n","    valid_logs = valid_epoch.run(valid_loader, n_epoch, i, train=False)\r\n","\r\n","    # do something (save model, change lr, etc.)\r\n","    if valid_logs['iou_score'] > max_score:\r\n","        max_score = valid_logs['iou_score']\r\n","        torch.save(model, model_path)\r\n","        print('Model saved!')\r\n","        \r\n","    if i == 10:\r\n","        optimizer.param_groups[0]['lr'] = 1e-5\r\n","        print('Decrease decoder learning rate to 1e-5!')\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgTL7ZYUPgRv"},"source":["valid_logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qSFPz7a-K1AF"},"source":["torch.save(model, model_path)"],"execution_count":null,"outputs":[]}]}