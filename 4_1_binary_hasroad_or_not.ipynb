{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_1_binary_hasroad_or_not.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rAIMmWFo2iKp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDvmIZJiQeha"},"source":["%%time\n","import zipfile\n","for i in [0, 1, 2, 3]:\n","    with zipfile.ZipFile(f'drive/MyDrive/OffroadSegmentation/data/train_images_A_{i}.zip') as existing_zip:\n","        existing_zip.extractall('train_images')\n","\n","with zipfile.ZipFile(f'drive/MyDrive/OffroadSegmentation/data/train_annotations_A.zip') as existing_zip:\n","    existing_zip.extractall('train_annotations')\n","\n","!cp -r drive/MyDrive/OffroadSegmentation/data/precision_test_images precision_test_images\n","\n","!pip install git+https://github.com/rwightman/pytorch-image-models.git \n","!pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n","!pip install pytorch-lightning\n","!pip install segmentation-models-pytorch "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKG3nqextMsh"},"source":["import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import glob\r\n","\r\n","from torch.utils.data import DataLoader\r\n","from torch.utils.data import Dataset as BaseDataset\r\n","\r\n","import torch\r\n","import numpy as np\r\n","\r\n","import albumentations as albu\r\n","from tqdm import tqdm_notebook as tqdm\r\n","\r\n","\r\n","import pytorch_lightning as pl\r\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\r\n","from pytorch_lightning.metrics.functional import accuracy\r\n","from sklearn.model_selection import StratifiedKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOnrwd1o9Pnk"},"source":["df = pd.read_csv('/content//drive/MyDrive/Signate-OffroadSegmentation/data/5fold_validation.csv')\r\n","df['file_name'] = df['png_name']\r\n","\r\n","fold = 0\r\n","\r\n","t_df = df[df['type'] == 'train_images']\r\n","\r\n","t_df['has_road'] = 0\r\n","t_df.loc[t_df['road'] > t_df['dirt road'] , 'has_road'] = 1\r\n","\r\n","train_df = t_df[t_df['fold'] != fold]\r\n","valid_df = t_df[t_df['fold'] == fold]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mLJ76SnyXT8"},"source":["t_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfq4d5sgbuTu"},"source":["class Dataset(BaseDataset):\r\n","    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\r\n","    \r\n","    Args:\r\n","        images_dir (str): path to images folder\r\n","        masks_dir (str): path to segmentation masks folder\r\n","        class_values (list): values of classes to extract from segmentation mask\r\n","        augmentation (albumentations.Compose): data transfromation pipeline \r\n","            (e.g. flip, scale, etc.)\r\n","        preprocessing (albumentations.Compose): data preprocessing \r\n","            (e.g. noralization, shape manipulation, etc.)\r\n","    \r\n","    \"\"\"\r\n","    \r\n","    \r\n","    def __init__(\r\n","            self, \r\n","            df, \r\n","            augmentation=None, \r\n","            preprocessing=None,\r\n","    ):\r\n","        self.images_fps = df['png_name'].values\r\n","        self.label = df['has_road'].values\r\n","                \r\n","        self.augmentation = augmentation\r\n","        self.preprocessing = preprocessing\r\n","    \r\n","    def __getitem__(self, i):\r\n","        \r\n","        # read data\r\n","        image = cv2.imread(self.images_fps[i])\r\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","\r\n","        label = self.label[i]\r\n","\r\n","        # apply augmentations\r\n","        if self.augmentation:\r\n","            sample = self.augmentation(image=image)\r\n","            image = sample['image']\r\n","        \r\n","        # apply preprocessing\r\n","        if self.preprocessing:\r\n","            sample = self.preprocessing(image=image)\r\n","            image = sample['image']\r\n","            \r\n","        return image, label\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.images_fps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pqQRR59EBiee"},"source":["def get_training_augmentation():\r\n","    IMAGE_SIZE = [1080, 1920]\r\n","    train_transform = [\r\n","        albu.Resize(*[1056, 1920]),\r\n","        albu.PadIfNeeded(1056, 1920),\r\n","\r\n","    #     albu.HorizontalFlip(p=0.5),\r\n","\r\n","    #     albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\r\n","\r\n","        # albu.PadIfNeeded(min_height=1080, min_width=1920, always_apply=True, border_mode=0),\r\n","        # albu.RandomCrop(height=960, width=960, always_apply=True),\r\n","        # albu.RandomCrop(height=IMAGE_SIZE[0], width=IMAGE_SIZE[0], always_apply=True),\r\n","\r\n","        # albu.IAAAdditiveGaussianNoise(p=0.2),\r\n","        # albu.IAAPerspective(p=0.5),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.CLAHE(p=1),\r\n","        #         albu.RandomBrightness(p=1),\r\n","        #         albu.RandomGamma(p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.IAASharpen(p=1),\r\n","        #         albu.Blur(blur_limit=3, p=1),\r\n","        #         albu.MotionBlur(blur_limit=3, p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","\r\n","        # albu.OneOf(\r\n","        #     [\r\n","        #         albu.RandomContrast(p=1),\r\n","        #         albu.HueSaturationValue(p=1),\r\n","        #     ],\r\n","        #     p=0.9,\r\n","        # ),\r\n","    ]\r\n","    return albu.Compose(train_transform)\r\n","\r\n","\r\n","def get_validation_augmentation():\r\n","    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\r\n","    IMAGE_SIZE = [1080, 1920]\r\n","    test_transform = [\r\n","        albu.Resize(*[1056, 1920]),\r\n","        albu.PadIfNeeded(1056, 1920),\r\n","    ]\r\n","    return albu.Compose(test_transform)\r\n","\r\n","\r\n","def to_tensor(x, **kwargs):\r\n","    return x.transpose(2, 0, 1).astype('float32')\r\n","\r\n","\r\n","def get_preprocessing():\r\n","    \"\"\"Construct preprocessing transform\r\n","    \r\n","    Args:\r\n","        preprocessing_fn (callbale): data normalization function \r\n","            (can be specific for each pretrained neural network)\r\n","    Return:\r\n","        transform: albumentations.Compose\r\n","    \r\n","    \"\"\"\r\n","    \r\n","    _transform = [\r\n","        # albu.Lambda(image=preprocessing_fn),\r\n","        albu.Lambda(image=to_tensor),\r\n","    ]\r\n","    return albu.Compose(_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0z4FyGzx1B9W"},"source":["from torch import nn\r\n","import torch.nn.functional as F\r\n","import timm\r\n","\r\n","class LightSystem(pl.LightningModule):\r\n","\r\n","    def __init__(self, model_name='efficientnet_b0', pretrained=True):\r\n","        super(LightSystem, self).__init__()\r\n","        self.model = timm.create_model(\r\n","            model_name, pretrained, num_classes=1000,\r\n","        )\r\n","\r\n","        in_features = self.model.classifier.in_features\r\n","        self.model.classifier = nn.Linear(in_features, 1)\r\n","\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        logit = self.model(x)\r\n","        logit = torch.sigmoid(logit)\r\n","\r\n","        return logit\r\n","\r\n","    def training_step(self, batch, batch_idx):\r\n","        # REQUIRED\r\n","        x, y = batch\r\n","        y_hat = self.forward(x)\r\n","        loss = F.binary_cross_entropy(torch.sigmoid(y_hat).flatten(), y.float())\r\n","        # loss = F.mse_loss(y_hat.flatten(), y.float())\r\n","        return {'loss': loss}\r\n"," \r\n","    def validation_step(self, batch, batch_idx):\r\n","        # OPTIONAL\r\n","        x, y = batch\r\n","        out = self.forward(x)\r\n","        loss = F.binary_cross_entropy(torch.sigmoid(out).flatten(), y.float())\r\n","        # loss = F.mse_loss(out.flatten(), y.float())\r\n","        return {'val_loss': loss}\r\n"," \r\n","    def validation_end(self, outputs):\r\n","        # OPTIONAL\r\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\r\n","        return {'avg_val_loss': avg_loss}\r\n"," \r\n","    def configure_optimizers(self):\r\n","        # REQUIRED\r\n","        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\r\n","        return optimizer\r\n"," \r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WISkNfyo2MQ9"},"source":["ls = LightSystem()\r\n","train_dataset = Dataset(train_df,\r\n","                        augmentation=get_training_augmentation(), \r\n","                        preprocessing=get_preprocessing(),\r\n","                        )\r\n","                        \r\n","valid_dataset = Dataset(valid_df,\r\n","                        augmentation=get_validation_augmentation(), \r\n","                        preprocessing=get_preprocessing(),\r\n","                        )\r\n","\r\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=12)\r\n","valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=4)                \r\n","\r\n","trainer = pl.Trainer(max_epochs=50, gpus=1)\r\n","trainer.fit(ls, train_loader, valid_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlbBrwUeZE-E"},"source":["trainer.save_checkpoint('/content//drive/MyDrive/OffroadSegmentation/pl_checkpoint/offroad_efficient_net_b0_has_road_or_not_2.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wOxY3L2YwRB"},"source":["# best_checkpoints = trainer.checkpoint_callback.best_model_path\r\n","pretrained_model = LightSystem().load_from_checkpoint(checkpoint_path = '/content//drive/MyDrive/OffroadSegmentation/pl_checkpoint/offroad_efficient_net_b0_has_road_or_not_2.ckpt')\r\n","pretrained_model = pretrained_model.to(\"cuda\")\r\n","pretrained_model.eval()\r\n","pretrained_model.freeze()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sQBmE2eaiJp"},"source":["fin_out = []\r\n","for data in tqdm(valid_loader):\r\n","    y_hat = pretrained_model(data[0].to(\"cuda\"))\r\n","    # y_hat = torch.argmax(y_hat,dim=1)\r\n","    fin_out.extend(y_hat.cpu().detach().numpy().tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GO6qknb9ZmPB"},"source":["df_val_result = valid_df.copy()\r\n","df_val_result['pred_has_road'] = np.array(fin_out).reshape(len(fin_out))\r\n","df_val_result['pred_has_road'] = df_val_result['pred_has_road'].round(3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2g-ZYoeI6xHN"},"source":["df_val_result[df_val_result['has_road'] == 1].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdgzC6LoBF4C"},"source":["# def visualize(**images):\r\n","#     \"\"\"PLot images in one row.\"\"\"\r\n","#     n = len(images)\r\n","#     plt.figure(figsize=(16, 5))\r\n","#     for i, (name, image) in enumerate(images.items()):\r\n","#         plt.subplot(1, n, i + 1)\r\n","#         plt.xticks([])\r\n","#         plt.yticks([])\r\n","#         plt.title(' '.join(name.split('_')).title())\r\n","#         plt.imshow(image)\r\n","#     plt.show()\r\n","\r\n","# val_fold = 4\r\n","# df = df_val_result[(df_val_result['pred_has_road'] < 0.9) & (df_val_result['has_road'] == 1)]\r\n","\r\n","# for i, row in df.iloc[0:5].iterrows():\r\n","#     image = cv2.imread(row['png_name'])\r\n","#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","#     mask = cv2.imread(row['annotation'])\r\n","#     mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\r\n","\r\n","#     visualize(image=image, mask=mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SPEeQQJBGzb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRcrs_x4kmhu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zyzxHfa4knZG"},"source":["import segmentation_models_pytorch as smp\r\n","\r\n","class TestDataset(BaseDataset):\r\n","    \r\n","    def __init__(\r\n","            self, \r\n","            df, \r\n","            augmentation=None, \r\n","            preprocessing=None,\r\n","    ):\r\n","        self.images_fps = df['file_name'].values\r\n","                \r\n","        self.augmentation = augmentation\r\n","        self.preprocessing = preprocessing\r\n","    \r\n","    def __getitem__(self, i):\r\n","        \r\n","        # read data\r\n","        image = cv2.imread(self.images_fps[i])\r\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n","\r\n","        # apply augmentations\r\n","        if self.augmentation:\r\n","            sample = self.augmentation(image=image)\r\n","            image = sample['image']\r\n","        \r\n","        # apply preprocessing\r\n","        if self.preprocessing:\r\n","            sample = self.preprocessing(image=image)\r\n","            image = sample['image']\r\n","            \r\n","        return image\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.images_fps)\r\n","\r\n","\r\n","def get_preprocessing(preprocessing_fn):\r\n","    \"\"\"Construct preprocessing transform\r\n","    \r\n","    Args:\r\n","        preprocessing_fn (callbale): data normalization function \r\n","            (can be specific for each pretrained neural network)\r\n","    Return:\r\n","        transform: albumentations.Compose\r\n","    \r\n","    \"\"\"\r\n","\r\n","\r\n","    if preprocessing_fn:\r\n","        _transform = [\r\n","            albu.Lambda(image=preprocessing_fn),\r\n","            albu.Lambda(image=to_tensor),\r\n","        ]\r\n","    else:\r\n","        _transform = [\r\n","            albu.Lambda(image=to_tensor),\r\n","        ]\r\n","\r\n","    return albu.Compose(_transform)\r\n","\r\n","ENCODER = 'resnet34'\r\n","ENCODER_WEIGHTS = 'imagenet'\r\n","preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MOMwVNzkoC2"},"source":["# test data を 2値分類\r\n","\r\n","pretrained_model = LightSystem().load_from_checkpoint('/content//drive/MyDrive/OffroadSegmentation/pl_checkpoint/offroad_efficient_net_b0_has_road_or_not_2.ckpt')\r\n","pretrained_model = pretrained_model.to(\"cuda\")\r\n","pretrained_model.eval()\r\n","pretrained_model.freeze()\r\n","\r\n","png_l = glob.glob('precision_test_images/*.png')\r\n","\r\n","df_test_path = pd.DataFrame()\r\n","df_test_path['file_name'] = np.sort(png_l)\r\n","df_test_path['png_name'] = df_test_path['file_name'].str.split('/', expand=True)[1]\r\n","\r\n","test_dataset = TestDataset(\r\n","    df_test_path, \r\n","    augmentation=get_validation_augmentation(),\r\n","    preprocessing=get_preprocessing(None),\r\n",")\r\n","\r\n","test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\r\n","\r\n","fin_out = []\r\n","for data in tqdm(test_loader):\r\n","    y_hat = pretrained_model(data.to(\"cuda\"))\r\n","    # y_hat = torch.argmax(y_hat,dim=1)\r\n","    fin_out.extend(y_hat.cpu().detach().numpy().tolist())\r\n","\r\n","df_test_path['pred_has_road'] = np.array(fin_out).reshape(len(fin_out))\r\n","df_test_path['f_has_road'] = df_test_path['pred_has_road'] > 0.9\r\n","\r\n","df_test_path.to_csv('/content//drive/MyDrive/Signate-OffroadSegmentation/data/test_2stage_binary.csv')"],"execution_count":null,"outputs":[]}]}