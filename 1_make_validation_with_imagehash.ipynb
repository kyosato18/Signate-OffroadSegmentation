{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_make_validation_with_imagehash.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rAIMmWFo2iKp"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LDvmIZJiQeha"},"source":["%%time\n","import zipfile\n","for i in [0, 1, 2, 3]:\n","    with zipfile.ZipFile(f'drive/MyDrive/Signate-OffroadSegmentation/data/train_images_A_{i}.zip') as existing_zip:\n","        existing_zip.extractall('train_images')\n","\n","with zipfile.ZipFile(f'drive/MyDrive/Signate-OffroadSegmentation/data/train_annotations_A.zip') as existing_zip:\n","    existing_zip.extractall('train_annotations')\n","\n","!cp -r drive/MyDrive/OffroadSegmentation/data/precision_test_images precision_test_images\n","\n","!pip install segmentation-models-pytorch \n","!pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n","!pip install imagehash"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LnBrMz5Mw4wo"},"source":["import os\r\n","import pandas as pd\r\n","import numpy as np\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","import glob\r\n","\r\n","from torch.utils.data import DataLoader\r\n","from torch.utils.data import Dataset as BaseDataset\r\n","\r\n","import torch\r\n","import numpy as np\r\n","\r\n","import albumentations as albu\r\n","from tqdm import tqdm\r\n","import imagehash\r\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bjBIPP_s9tbP"},"source":["## 1. imagehash\r\n"]},{"cell_type":"code","metadata":{"id":"yXkKG7-lqi92"},"source":["%%time\r\n","def run(png_list):\r\n","\r\n","    funcs = [\r\n","        imagehash.average_hash,\r\n","        imagehash.phash,\r\n","        imagehash.dhash,\r\n","        imagehash.whash,\r\n","    ]\r\n","\r\n","    petids = []\r\n","    hashes = []\r\n","    for path in tqdm(png_list):\r\n","\r\n","        image = Image.open(path)\r\n","        imageid = path.split('/')[-1].split('.')[0]\r\n","\r\n","        petids.append(imageid)\r\n","        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\r\n","\r\n","    return petids, np.array(hashes)\r\n","\r\n","png_list = glob.glob('train_images/train_images_*/*.png')\r\n","png_list.extend(glob.glob('precision_test_images/*.png'))\r\n","png_list = np.sort(png_list)\r\n","\r\n","petids, hashes_all = run(png_list)\r\n","hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()\r\n","sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])\r\n","\r\n","threshold = 0.90\r\n","duplicates = np.where(sims > threshold)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GdBrdv4GKw0K"},"source":["# visualize\r\n","\r\n","# count = 5\r\n","# tmp = 0\r\n","# paths = png_list\r\n","\r\n","# pairs = {}\r\n","# for i,j in zip(*duplicates):\r\n","#     if i == j:\r\n","#         continue\r\n","\r\n","#     path1 = paths[i]\r\n","#     path2 = paths[j]\r\n","#     print(path1)\r\n","#     print(path2)\r\n","#     print(sims[i, j])\r\n","\r\n","#     image1 = cv2.imread(path1)\r\n","#     image2 = cv2.imread(path2)\r\n","\r\n","#     if image1.shape[0] > image1.shape[1] / 2:\r\n","#         fig,ax = plt.subplots(figsize=(20,20), ncols=2)\r\n","#     elif image1.shape[1] > image1.shape[0] / 2:\r\n","#         fig,ax = plt.subplots(figsize=(20,20), nrows=2)\r\n","#     else:\r\n","#         fig,ax = plt.subplots(figsize=(20,30), nrows=2)\r\n","#     ax[0].imshow(image1)\r\n","#     ax[1].imshow(image2)\r\n","#     plt.show()\r\n","    \r\n","#     tmp += 1\r\n","#     if tmp > count:\r\n","#         break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RknMQf64vT7a"},"source":["# find duplicate images\r\n","import networkx as nx\r\n","g1 = nx.Graph()\r\n","for i, j in tqdm(zip(*duplicates)):\r\n","    g1.add_edge(i, j)\r\n","\r\n","duplicates_groups = list(list(x) for x in nx.connected_components(g1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxJRsNYyGJRT"},"source":["# make df_imagehash\r\n","df_imagehash = pd.DataFrame()\r\n","df_imagehash['png_name'] = png_list\r\n","\r\n","df_imagehash['duplicate_id'] = 999\r\n","for i, d_grp in enumerate(duplicates_groups):\r\n","    df_imagehash.loc[d_grp, 'duplicate_id'] = i\r\n","\r\n","df_imagehash['type'] = df_imagehash['png_name'].str.split('/', expand=True)[0]\r\n","df_nunique = df_imagehash.groupby('duplicate_id')['type'].nunique().reset_index().rename(columns={'type':'nunique_type'}) # testとtrainの両方にあるか否か\r\n","df_imagehash = pd.merge(df_imagehash, df_nunique, how='left', on='duplicate_id')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWPm8Mn294bl"},"source":["# make 5fold\r\n","\r\n","df_imagehash['fold'] = 999\r\n","dup_vc = df_imagehash[(df_imagehash['type'] == 'train_images') & \r\n","                      (df_imagehash['nunique_type'] == 1)]['duplicate_id'].value_counts()\r\n","\r\n","for i in range(5):\r\n","    df_imagehash.loc[df_imagehash['duplicate_id'].isin(dup_vc.index[i::5]), 'fold'] = i\r\n","    df_imagehash.loc[(df_imagehash.index % 5 == i) & (df_imagehash['duplicate_id'] == 999), 'fold'] = i"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TYusChknA5gx"},"source":["# 2. add annotation area info"]},{"cell_type":"code","metadata":{"id":"bFB053_kJmjN"},"source":["# add annotation area info\r\n","\r\n","anno_list = {'road': [128, 64, 128], \r\n","             'dirt road': [255, 128, 128],\r\n","             'other obstacle': [0, 0, 70]}\r\n","png_l = glob.glob('train_images/train_images_*/*.png')\r\n","\r\n","df_train = pd.DataFrame()\r\n","df_train['png_name'] = np.sort(png_l)\r\n","df_train['annotation'] = np.sort(glob.glob('train_annotations/train_annotations_*/*.png'))\r\n","df_train['road'] = 0\r\n","df_train['dirt road'] = 0\r\n","df_train['other obstacle'] = 0\r\n","\r\n","for i, row in tqdm(df_train.iterrows()):\r\n","    for category in ['road', 'dirt road', 'other obstacle']:\r\n","        mask = cv2.imread(row['annotation'])\r\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\r\n","        \r\n","        a = anno_list[category]\r\n","        df_train.loc[i, category] = ((mask[:, :, 0] == a[0]) & (mask[:, :, 1] == a[1]) & (mask[:, :, 2] == a[2])).sum()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cE0_b_RLNtOO"},"source":["df = pd.merge(df_imagehash, df_train, on='png_name', how='left')\r\n","df.to_csv('drive/MyDrive/Signate-OffroadSegmentation/data/5fold_validation.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vEZzZ2C6UBXO"},"source":["df"],"execution_count":null,"outputs":[]}]}